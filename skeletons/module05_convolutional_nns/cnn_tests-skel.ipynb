{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convolutional Neural Networks for Image Recognition\n",
    "## Advanced Machine Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import fnmatch\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.layers import InputLayer\n",
    "from tensorflow.keras.layers import Convolution2D, Dense, MaxPooling2D, Flatten, BatchNormalization, Dropout\n",
    "from tensorflow.keras import Sequential\n",
    "import random\n",
    "import re\n",
    "\n",
    "# pip install pypng\n",
    "import png\n",
    "import sklearn.metrics\n",
    "\n",
    "# Provided \n",
    "from core50 import *\n",
    "\n",
    "##################\n",
    "# Configure figure parameters\n",
    "\n",
    "FONTSIZE = 18\n",
    "FIGURE_SIZE = (10,4)\n",
    "FIGURE_SIZE2 = (10,10)\n",
    "\n",
    "plt.rcParams.update({'font.size': FONTSIZE})\n",
    "plt.rcParams['figure.figsize'] = FIGURE_SIZE\n",
    "# Default tick label size\n",
    "plt.rcParams['xtick.labelsize'] = FONTSIZE\n",
    "plt.rcParams['ytick.labelsize'] = FONTSIZE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load up a single image & view it\n",
    "directory = '/home/fagg/datasets/core50/core50_128x128/s1/o21'\n",
    "files = os.listdir(directory)\n",
    "\n",
    "r = png.Reader(directory + \"/\" + files[0])\n",
    "it = r.read()\n",
    "image_2d = np.vstack(map(np.uint8, it[2]))\n",
    "image_3d = np.reshape(image_2d,\n",
    "                         (128,128,3))\n",
    "\n",
    "plt.imshow(image_3d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data Sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## File location\n",
    "directory_base = '/home/fagg/datasets/core50/core50_128x128'\n",
    "\n",
    "# Training set: define which files to load for each object\n",
    "#val = '.*[05].png'\n",
    "val_files = '.*[0].png'\n",
    "\n",
    "### Positive cases\n",
    "# Define which objects to load\n",
    "#object_list = ['o25', 'o22', 'o23', 'o24']\n",
    "object_list = ['o21']\n",
    "\n",
    "# Define which conditions to load\n",
    "#condition_list = ['s1', 's2', 's3', 's4', 's5', 's7', 's8', 's9', 's10', 's11']\n",
    "#condition_list = ['s1', 's2', 's3', 's4']\n",
    "condition_list = ['s1']\n",
    "\n",
    "# Load all of the objects/condition\n",
    "ins_pos = load_multiple_image_sets_from_directories(directory_base, condition_list, object_list, val_files)\n",
    "\n",
    "### Negative cases\n",
    "# Define which objects to load\n",
    "#object_list2 = ['o45', 'o42', 'o43', 'o44']\n",
    "object_list2 = ['o41']\n",
    "ins_neg = load_multiple_image_sets_from_directories(directory_base, condition_list, object_list2, val_files)\n",
    "\n",
    "### Combine positives and negatives into a common data set\n",
    "outs_pos = np.append(np.ones((ins_pos.shape[0],1)), np.zeros((ins_pos.shape[0],1)), axis=1)\n",
    "outs_neg = np.append(np.zeros((ins_pos.shape[0],1)), np.ones((ins_pos.shape[0],1)), axis=1)\n",
    "\n",
    "ins = np.append(ins_pos, ins_neg, axis=0)\n",
    "outs = np.append(outs_pos, outs_neg, axis=0)\n",
    "\n",
    "########################################################################\n",
    "# Validation set\n",
    "# Define which files to load for each object\n",
    "val_files = '.*[5].png'\n",
    "\n",
    "### Positives\n",
    "# Define which objects to load\n",
    "object_list = ['o21']\n",
    "#object_list = ['o21']\n",
    "\n",
    "# Load the positives\n",
    "ins_pos_validation = load_multiple_image_sets_from_directories(directory_base, condition_list, object_list, val_files)\n",
    "\n",
    "### Negatives\n",
    "# Define objects\n",
    "object_list2 = ['o41']\n",
    "#object_list2 = ['o41']\n",
    "\n",
    "# Load the negative cases\n",
    "ins_neg_validation = load_multiple_image_sets_from_directories(directory_base, condition_list, object_list2, val_files)\n",
    "\n",
    "### Combine positives and negatives\n",
    "outs_pos_validation = np.append(np.ones((ins_pos_validation.shape[0], 1)), np.zeros((ins_pos_validation.shape[0], 1)), axis=1)\n",
    "outs_neg_validation = np.append(np.zeros((ins_pos_validation.shape[0], 1)), np.ones((ins_pos_validation.shape[0], 1)), axis=1)\n",
    "\n",
    "ins_validation = np.append(ins_pos_validation, ins_neg_validation, axis=0)\n",
    "outs_validation = np.append(outs_pos_validation, outs_neg_validation, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ins.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ins_validation.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outs_validation.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_classifier_network(image_size, nchannels, n_classes, lambda_l2=.0001, p_dropout=0.5):\n",
    "    model = Sequential()\n",
    "    model.add(InputLayer(input_shape=(image_size[0], image_size[1], nchannels)))\n",
    "   \n",
    "    ### Fill in detail\n",
    "    \n",
    "    print(model.summary())\n",
    "    \n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = create_classifier_network((ins.shape[1], ins.shape[2]), ins.shape[3], 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Callbacks\n",
    "early_stopping_cb = keras.callbacks.EarlyStopping(patience=10,\n",
    "                                                  restore_best_weights=True,\n",
    "                                                      min_delta=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "history = model.fit(x=ins, y=outs, epochs=100, verbose=1,\n",
    "                        validation_data=(ins_validation, outs_validation), \n",
    "                        callbacks=[early_stopping_cb])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_roc(model, ins, outs, ins_validation, outs_validation):\n",
    "    '''\n",
    "    Produce a ROC plot given a model, a set of inputs and the true outputs\n",
    "    \n",
    "    Assume that model produces N-class output; we will only look at the class 0 scores\n",
    "    '''\n",
    "    # Compute probabilistic predictions given images\n",
    "    pred = model.predict(ins)\n",
    "    # Compute false positive rate & true positive rate + AUC\n",
    "    fpr, tpr, thresholds = sklearn.metrics.roc_curve(outs[:,0], pred[:,0])\n",
    "    auc = sklearn.metrics.auc(fpr, tpr)\n",
    "    \n",
    "    # Compute probabilistic predictions given images\n",
    "    pred_val = model.predict(ins_validation)\n",
    "    # Compute false positive rate & true positive rate + AUC\n",
    "    fpr_val, tpr_val, thresholds_val = sklearn.metrics.roc_curve(outs_validation[:,0], pred_val[:,0])\n",
    "    auc_val = sklearn.metrics.auc(fpr_val, tpr_val)\n",
    "    \n",
    "    \n",
    "    # Generate the plot\n",
    "    plt.figure(1)\n",
    "    plt.axis('equal')\n",
    "    plt.plot([0,1], [0,1], 'k--')\n",
    "    plt.plot(fpr, tpr, 'b', label='Train AUC = {:.3f}'.format(auc))\n",
    "    plt.plot(fpr_val, tpr_val, 'r', label='Validation AUC = {:.3f}'.format(auc_val))\n",
    "    plt.legend(loc='best')\n",
    "    plt.xlabel('FPR', fontsize=FONTSIZE)\n",
    "    plt.ylabel('TPR', fontsize=FONTSIZE)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_roc(model, ins, outs, ins_validation, outs_validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize Model Internals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def intermediate_model_state(model, ins, layer_list):\n",
    "    '''\n",
    "    Return layer activations for intermediate layers in a model for a set of examples\n",
    "    \n",
    "    :param model: Model in question\n",
    "    :param ins: Input tensor (examples, rows, cols, channels)\n",
    "    :param layer_list: List of layer names to produce activations for\n",
    "    :returns: a list of numpy arrays\n",
    "    '''\n",
    "    # Translate layer names into corresponding output tensors\n",
    "    layer_outputs = [l.output for l in model.layers if l.name in layer_list]\n",
    "    \n",
    "    # Construct a new Keras model that outputs these tensors\n",
    "    # The internal structure of the model itself is referenced through the input and output tensor lists\n",
    "    new_model = keras.models.Model(inputs=model.input, outputs=layer_outputs)\n",
    "    \n",
    "    # Evaluate the new model\n",
    "    activations = new_model.predict(ins_validation)\n",
    "    \n",
    "    # Return a list of activation numpy arrays\n",
    "    return activations\n",
    "\n",
    "def visualize_state(activations, width=1, example=0, cmap='plasma'):\n",
    "    '''\n",
    "    Produce graphical representation of a set of image channels\n",
    "    \n",
    "    :param activations: numpy array (example, rows, cols, channels)\n",
    "    :param width: Number of images displayed horizontally\n",
    "    :param example: Index of example to display\n",
    "    :param cmap: Color map to use for plotting\n",
    "    '''\n",
    "    # Size of the individual images\n",
    "    nrows = activations.shape[1]\n",
    "    ncols = activations.shape[2]\n",
    "    # Number of channels\n",
    "    nfilters = activations.shape[3]\n",
    "    \n",
    "    # Tile all of the sub-images \n",
    "    grid = np.zeros((int((nfilters-1)/width + 1) * nrows, ncols * width))\n",
    "    \n",
    "    # Loop over image\n",
    "    for i in range(nfilters):\n",
    "        # Compute r,c of tile to place the ith image into\n",
    "        r = int(i / width)\n",
    "        c = i % width\n",
    "        grid[nrows*r: nrows*(r+1), ncols*c:ncols*(c+1)] = activations[example,:,:,i]\n",
    "        \n",
    "    # Plot\n",
    "    plt.matshow(grid, cmap=cmap) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute activations for 2 layers over a set of examples\n",
    "layer_list=['C1']\n",
    "activations = intermediate_model_state(model, ins_validation, layer_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot convolutional layers 1 and 2\n",
    "example=40\n",
    "plt.imshow(ins_validation[example,:,:,:])\n",
    "visualize_state(activations, width=10, example=example)\n",
    "#visualize_state(activations[0], width=10, example=example)\n",
    "#visualize_state(activations[1], width=20, example=example)\n",
    "#visualize_state(activations[2], width=20, example=example)\n",
    "#visualize_state(activations[3], width=30, example=example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
